{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "This section contains all the required imports for this model."
   ],
   "id": "4a54c48418802722"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T17:48:40.415202Z",
     "start_time": "2025-02-27T17:48:39.678231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ],
   "id": "6c9108f26313a2fc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Pre-processing\n",
    "The data for this model can be found [here](https://archive.ics.uci.edu/dataset/542/internet+firewall+data). Once the data has been imported we drop any rows with empty values. After this we map the different types of ports to their respective port numbers. We then apply this map to the `Destination Port` column. After this we encode the column with a label encoder. After this we drop any unnecessary columns."
   ],
   "id": "8b570f470a1d448"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-27T17:48:40.480880Z",
     "start_time": "2025-02-27T17:48:40.419497Z"
    }
   },
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('log2.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Map Ports to Services\n",
    "port_to_service = {53: \"DNS\", 80: \"HTTP\", 443: \"HTTPS\", 3389: \"RDP\", 22: \"SSH\", 123: \"NTP\"}\n",
    "df[\"TrafficType\"] = df[\"Destination Port\"].map(port_to_service).fillna(\"Unknown\")\n",
    "\n",
    "# Encode TrafficType\n",
    "le = LabelEncoder()\n",
    "df[\"TrafficType\"] = le.fit_transform(df[\"TrafficType\"])\n",
    "\n",
    "df = df.drop([\"Source Port\", \"Destination Port\", \"NAT Source Port\", \"NAT Destination Port\", \"Action\"], axis=1)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Bytes  Bytes Sent  Bytes Received  Packets  Elapsed Time (sec)  pkts_sent  \\\n",
       "0    177          94              83        2                  30          1   \n",
       "1   4768        1600            3168       19                  17         10   \n",
       "2    238         118             120        2                1199          1   \n",
       "3   3327        1438            1889       15                  17          8   \n",
       "4  25358        6778           18580       31                  16         13   \n",
       "\n",
       "   pkts_received  TrafficType  \n",
       "0              1            0  \n",
       "1              9            4  \n",
       "2              1            6  \n",
       "3              7            4  \n",
       "4             18            2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bytes</th>\n",
       "      <th>Bytes Sent</th>\n",
       "      <th>Bytes Received</th>\n",
       "      <th>Packets</th>\n",
       "      <th>Elapsed Time (sec)</th>\n",
       "      <th>pkts_sent</th>\n",
       "      <th>pkts_received</th>\n",
       "      <th>TrafficType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177</td>\n",
       "      <td>94</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4768</td>\n",
       "      <td>1600</td>\n",
       "      <td>3168</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238</td>\n",
       "      <td>118</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>1199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3327</td>\n",
       "      <td>1438</td>\n",
       "      <td>1889</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25358</td>\n",
       "      <td>6778</td>\n",
       "      <td>18580</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Fitting\n",
    "The first thing we do when fitting the data to our model is defining our features and our target. Once this is done we split the data into test data and training data into a 70:30 split respectively. Once this has been done we apply the Synthetic Minority Oversampling Technique (SMOTE) to help balance our minority classes. Then, we scale both the resampled training data and the test data to ensure all features are on the same scale. Finally, we train our model with 3 neighbors and distance-based weighting on the scaled training data and use it to predict results on the test set."
   ],
   "id": "4e807eae605b0e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T17:48:41.671421Z",
     "start_time": "2025-02-27T17:48:40.601958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Features and Target\n",
    "X = df.drop([\"TrafficType\"], axis=1)\n",
    "y = df[\"TrafficType\"]\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.3)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(sampling_strategy=\"not majority\")  # Balance all classes\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights=\"distance\")\n",
    "knn.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred = knn.predict(X_test_scaled)"
   ],
   "id": "36a683b1ef39b7bc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prediction\n",
    "Once our data has been fitted, we decode our predictions and evaluate them using a classification report and accuracy score."
   ],
   "id": "6bc3a835679517da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T17:48:42.222540Z",
     "start_time": "2025-02-27T17:48:41.689224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decode Predictions\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test_labels, y_pred_labels))"
   ],
   "id": "805cf2edca488ca9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DNS       0.98      0.97      0.98     10723\n",
      "        HTTP       0.62      0.74      0.68      2840\n",
      "       HTTPS       0.87      0.84      0.86      8117\n",
      "         NTP       0.36      0.74      0.48       128\n",
      "         RDP       0.54      0.81      0.65       126\n",
      "         SSH       0.26      0.19      0.22        83\n",
      "     Unknown       0.98      0.97      0.98     23856\n",
      "\n",
      "    accuracy                           0.93     45873\n",
      "   macro avg       0.66      0.75      0.69     45873\n",
      "weighted avg       0.94      0.93      0.93     45873\n",
      "\n",
      "Accuracy Score: 0.9312885575392933\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
